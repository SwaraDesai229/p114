{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SwaraDesai229/p114/blob/main/Project_114_TEXT_PRE_PROCESSING.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "lZJn4XMeQohi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d05ed245-23d0-4957-9383-b067e675d0b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'product_dataset'...\n",
            "remote: Enumerating objects: 11, done.\u001b[K\n",
            "remote: Counting objects: 100% (11/11), done.\u001b[K\n",
            "remote: Compressing objects: 100% (10/10), done.\u001b[K\n",
            "remote: Total 11 (delta 0), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (11/11), 3.08 MiB | 8.90 MiB/s, done.\n"
          ]
        }
      ],
      "source": [
        "# Load the dataset from Github repositoy\n",
        "!git clone https://github.com/procodingclass/product_dataset.git\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make a dataframe using the 'pandas' module\n",
        "import pandas as pd\n",
        "dataframe = pd.read_excel('/content/product_dataset/updated_product_dataset.xlsx')\n",
        "#print(dataframe.head())\n",
        " print(dataframe.head()"
      ],
      "metadata": {
        "id": "i2ck3i9ycNXq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 133
        },
        "outputId": "203f03d2-65b1-4a11-b2d8-15d121bd60f3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-5a3c591d2665>\"\u001b[0;36m, line \u001b[0;32m5\u001b[0m\n\u001b[0;31m    print(dataframe.head()\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataframe[\"Emotion\"].unique()"
      ],
      "metadata": {
        "id": "ahpKP4Xc4ep6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encode_product={\"Positive\":0,\"Neutral\":1,\"Negative\":2}"
      ],
      "metadata": {
        "id": "AfK6S9KJ4kQ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tSKMj-hSYSAv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataframe.replace(encode_product,inplace=True)"
      ],
      "metadata": {
        "id": "EnTzj4gB4tk9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataframe.head()"
      ],
      "metadata": {
        "id": "S-wAZcLH4trn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_sentences=[]\n",
        "training_labels = []\n",
        "# append text and emotions in the list using the 'loc' method\n",
        "for i in range(len(dataframe)):\n",
        "  sentence = dataframe.loc[i,\"Text\"]\n",
        "  training_sentences.append(sentence)\n",
        "  label = dataframe.loc[i,\"Emotion\"]\n",
        "  training_labels.append(label)\n",
        "#Check a random text and label of the list\n",
        "training_sentences[50],training_labels[50]"
      ],
      "metadata": {
        "id": "FlQQaFlZ425n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "#Define parameters for Tokenizer\n",
        "vocab_size=10000\n",
        "embedding_dim = 16\n",
        "oov_tok = \"<OOV>\"\n",
        "training_size = 20000\n",
        "tokenizer=Tokenizer(num_words=vocab_size,oov_token=oov_tok)\n",
        "tokenizer.fit_on_texts(training_sentences)\n",
        "#Create a word_index dictionary\n",
        "word_index = tokenizer.word_index\n",
        "#Check the tokenized sequence\n",
        "word_index[\"wrong\"]"
      ],
      "metadata": {
        "id": "7zns_bd046ky"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_sequences = tokenizer.texts_to_sequences(training_sentences)\n",
        "print(training_sequences[0])\n",
        "print(training_sequences[1])\n",
        "print(training_sequences[2])"
      ],
      "metadata": {
        "id": "VCU0rS1646r-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "#Define parameters for pad_sequences\n",
        "padding_type = 'post'\n",
        "max_length = 100\n",
        "trunc_type='post'\n",
        "training_padded = pad_sequences(training_sequences,maxlen=max_length, padding=padding_type,truncating=trunc_type)\n",
        "\n",
        "#Check the padded sequence\n",
        "training_padded\n",
        "print(training_padded[0:3])"
      ],
      "metadata": {
        "id": "yUbgPTXQDiQC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Employee:\n",
        "  def __init__(self,name,Empid):\n",
        "    self.name=name\n",
        "    self.Empid=Empid\n",
        "    print(self.Empid)\n",
        "std=Employee(\"Jhon\",1)\n",
        "std.Empid=2\n",
        "\n"
      ],
      "metadata": {
        "id": "N0IXpIsYWL2_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "#Define parameters for pad_sequences\n",
        "padding_type = 'post'\n",
        "max_length = 100\n",
        "trunc_type='post'\n",
        "dataframe = pad_sequences(training_sequences,maxlen=max_length, padding=padding_type,truncating=trunc_type)\n",
        "\n",
        "#Check the padded sequence\n",
        "dataframe\n",
        "print(dataframe[0:3])"
      ],
      "metadata": {
        "id": "xNbhLWNe-D4x"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}